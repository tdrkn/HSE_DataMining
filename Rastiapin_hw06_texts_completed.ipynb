{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffq6A2-ifzAA"
   },
   "source": [
    "# Интеллектуальный анализ данных – весна 2025\n",
    "# Домашнее задание 6: классификация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPcxtekTA1Sm"
   },
   "source": [
    "Правила:\n",
    "\n",
    "\n",
    "\n",
    "*   Домашнее задание оценивается в 10 баллов.\n",
    "*   Можно использовать без доказательства любые результаты, встречавшиеся на лекциях или семинарах по курсу, если получение этих результатов не является вопросом задания.\n",
    "*  Можно использовать любые свободные источники с *обязательным* указанием ссылки на них.\n",
    "*  Плагиат не допускается. При обнаружении случаев списывания, 0 за работу выставляется всем участникам нарушения, даже если можно установить, кто у кого списал.\n",
    "*  Старайтесь сделать код как можно более оптимальным. В частности, будет штрафоваться использование циклов в тех случаях, когда операцию можно совершить при помощи инструментов библиотек, о которых рассказывалось в курсе.\n",
    "* Если в задании есть вопрос на рассуждение, то за отсутствие ответа на него балл за задание будет снижен вполовину."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itRtFtrOf0_b"
   },
   "source": [
    "В этом домашнем задании вам предстоит построить классификатор текстов.\n",
    "\n",
    "Будем предсказывать эмоциональную окраску твиттов о коронавирусе.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tNGRVO7_g9mz",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:08:38.153629Z",
     "start_time": "2025-05-18T13:08:38.147476Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import  List\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from string import punctuation"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "zOy8iHJQg_Ss",
    "outputId": "4f8b30f1-63c4-409d-cd09-0e9d8fe4cc62",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:08:54.210544Z",
     "start_time": "2025-05-18T13:08:38.196680Z"
    }
   },
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/hse-ds/iad-intro-ds/refs/heads/master/2025/homeworks/hw06_texts/tweets_coronavirus.csv', encoding='latin-1')\n",
    "df.sample(4)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       UserName  ScreenName          Location     TweetAt  \\\n",
       "7020      12335       57287   London, England  19-03-2020   \n",
       "30143     40828       85780      New York, NY  10-04-2020   \n",
       "24882     34254       79206  Norwich, England  06-04-2020   \n",
       "11332     17544       62496           Britain  21-03-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "7020   @sunny_hundal @sainsburys is my regular superm...            Negative  \n",
       "30143  This piece from @reuters talks about inflation...  Extremely Negative  \n",
       "24882  UK why aren t you matching physical copy price...            Negative  \n",
       "11332  #CoronaCrisis stop using trolleys in the super...            Negative  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>12335</td>\n",
       "      <td>57287</td>\n",
       "      <td>London, England</td>\n",
       "      <td>19-03-2020</td>\n",
       "      <td>@sunny_hundal @sainsburys is my regular superm...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30143</th>\n",
       "      <td>40828</td>\n",
       "      <td>85780</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>10-04-2020</td>\n",
       "      <td>This piece from @reuters talks about inflation...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24882</th>\n",
       "      <td>34254</td>\n",
       "      <td>79206</td>\n",
       "      <td>Norwich, England</td>\n",
       "      <td>06-04-2020</td>\n",
       "      <td>UK why aren t you matching physical copy price...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11332</th>\n",
       "      <td>17544</td>\n",
       "      <td>62496</td>\n",
       "      <td>Britain</td>\n",
       "      <td>21-03-2020</td>\n",
       "      <td>#CoronaCrisis stop using trolleys in the super...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2OiDog9ZBlS"
   },
   "source": [
    "Для каждого твитта указано:\n",
    "\n",
    "\n",
    "*   UserName - имя пользователя, заменено на целое число для анонимности\n",
    "*   ScreenName - отображающееся имя пользователя, заменено на целое число для анонимности\n",
    "*   Location - местоположение\n",
    "*   TweetAt - дата создания твитта\n",
    "*   OriginalTweet - текст твитта\n",
    "*   Sentiment - эмоциональная окраска твитта (целевая переменная)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZTMseDkhTC7"
   },
   "source": [
    "## Задание 1 Подготовка (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx2-odn9hdAW"
   },
   "source": [
    "Целевая переменная находится в колонке `Sentiment`.  Преобразуйте ее таким образом, чтобы она стала бинарной: 1 - если у твитта положительная или очень положительная эмоциональная окраска и 0 - если отрицательная или очень отрицательная."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "ZaQKQ1zEjP15",
    "outputId": "ba656a1e-5e53-4254-dbac-bdd95acd93d7",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:08:54.298750Z",
     "start_time": "2025-05-18T13:08:54.281360Z"
    }
   },
   "source": [
    "df['Sentiment'] = df['Sentiment'].replace({'Positive': 1, 'Extremely Positive': 1, 'Extremely Negative': 0, 'Negative': 0})\n",
    "df.sample(10)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wk/n09m_gw178zflz6sw7crwhz40000gn/T/ipykernel_3198/1831355944.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Sentiment'] = df['Sentiment'].replace({'Positive': 1, 'Extremely Positive': 1, 'Extremely Negative': 0, 'Negative': 0})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       UserName  ScreenName                       Location     TweetAt  \\\n",
       "6705      11947       56899                      Singapore  19-03-2020   \n",
       "5887      10946       55898                    Chicago, IL  19-03-2020   \n",
       "16780     24230       69182                            NaN  25-03-2020   \n",
       "21254     29722       74674                            NaN  01-04-2020   \n",
       "12291     18702       63654  Melbourne & Regional Victoria  22-03-2020   \n",
       "3342       7851       52803                 United Kingdom  18-03-2020   \n",
       "25373     34872       79824       Once Great Southern Land  06-04-2020   \n",
       "32018     43186       88138                            NaN  12-04-2020   \n",
       "25385     34891       79843                           Iraq  06-04-2020   \n",
       "10995     17139       62091                            NaN  21-03-2020   \n",
       "\n",
       "                                           OriginalTweet  Sentiment  \n",
       "6705   Luxury seafood supply hit by axed flights as #...          0  \n",
       "5887   Grocery store workers deserve hazard pay!!! #c...          0  \n",
       "16780  We would like to dedicate a post to thank to o...          1  \n",
       "21254  COVID 19 Ambulance Workers  Association on Str...          1  \n",
       "12291  Australians seem oblivious to the risks of 19 ...          0  \n",
       "3342   I only booked my hotel for only 2 days to see ...          1  \n",
       "25373  Wouldn't buy any from this maggot OR the super...          0  \n",
       "32018  Dropping fuel prices during COVID-19, but shou...          0  \n",
       "25385  2) OPEC+ et al cannot stop the damage generate...          1  \n",
       "10995  No grooming. No eating out. No online shopping...          0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>11947</td>\n",
       "      <td>56899</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>19-03-2020</td>\n",
       "      <td>Luxury seafood supply hit by axed flights as #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5887</th>\n",
       "      <td>10946</td>\n",
       "      <td>55898</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>19-03-2020</td>\n",
       "      <td>Grocery store workers deserve hazard pay!!! #c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16780</th>\n",
       "      <td>24230</td>\n",
       "      <td>69182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25-03-2020</td>\n",
       "      <td>We would like to dedicate a post to thank to o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21254</th>\n",
       "      <td>29722</td>\n",
       "      <td>74674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-04-2020</td>\n",
       "      <td>COVID 19 Ambulance Workers  Association on Str...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12291</th>\n",
       "      <td>18702</td>\n",
       "      <td>63654</td>\n",
       "      <td>Melbourne &amp; Regional Victoria</td>\n",
       "      <td>22-03-2020</td>\n",
       "      <td>Australians seem oblivious to the risks of 19 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3342</th>\n",
       "      <td>7851</td>\n",
       "      <td>52803</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>18-03-2020</td>\n",
       "      <td>I only booked my hotel for only 2 days to see ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25373</th>\n",
       "      <td>34872</td>\n",
       "      <td>79824</td>\n",
       "      <td>Once Great Southern Land</td>\n",
       "      <td>06-04-2020</td>\n",
       "      <td>Wouldn't buy any from this maggot OR the super...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32018</th>\n",
       "      <td>43186</td>\n",
       "      <td>88138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12-04-2020</td>\n",
       "      <td>Dropping fuel prices during COVID-19, but shou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25385</th>\n",
       "      <td>34891</td>\n",
       "      <td>79843</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>06-04-2020</td>\n",
       "      <td>2) OPEC+ et al cannot stop the damage generate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>17139</td>\n",
       "      <td>62091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21-03-2020</td>\n",
       "      <td>No grooming. No eating out. No online shopping...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGq1FxJ-kBo5"
   },
   "source": [
    "Сбалансированы ли классы?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "a7gdNtxckK5V",
    "outputId": "afd459d8-ba0d-4456-8a8a-44785db6c777",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:08:54.403900Z",
     "start_time": "2025-05-18T13:08:54.395121Z"
    }
   },
   "source": [
    "df['Sentiment'].value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "1    18046\n",
       "0    15398\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vL6g228CI662"
   },
   "source": [
    "Ну вообще, разница в 12%≈ не так критична ([источник гугл](https://developers.google.com/machine-learning/crash-course/overfitting/imbalanced-datasets?hl=ru)). Поэтому их можно назвать сбалансированными\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmSIBSsLk5Zz"
   },
   "source": [
    ":Выведете на экран информацию о пропусках в данных. Если пропуски присутствуют заполните их строкой 'Unknown'."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "UhUVRkR5kxa7",
    "outputId": "26722624-4440-4c9f-f207-e97e1e5f9dd7",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:08:54.552648Z",
     "start_time": "2025-05-18T13:08:54.538352Z"
    }
   },
   "source": [
    "df.isnull()\n",
    "\n",
    "df[df.isnull()] = 'Unknown'\n",
    "df.sample(3)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       UserName  ScreenName    Location     TweetAt  \\\n",
       "14836     21840       66792      France  23-03-2020   \n",
       "28780     39116       84068  Forodwaith  09-04-2020   \n",
       "16477     23861       68813     Unknown  24-03-2020   \n",
       "\n",
       "                                           OriginalTweet  Sentiment  \n",
       "14836  Marketers designing messaging to ease and enga...          1  \n",
       "28780  If you suspect a Scam please report it to the ...          0  \n",
       "16477  @acgrayling Despite Covid-19 pandemic deaths a...          0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>21840</td>\n",
       "      <td>66792</td>\n",
       "      <td>France</td>\n",
       "      <td>23-03-2020</td>\n",
       "      <td>Marketers designing messaging to ease and enga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28780</th>\n",
       "      <td>39116</td>\n",
       "      <td>84068</td>\n",
       "      <td>Forodwaith</td>\n",
       "      <td>09-04-2020</td>\n",
       "      <td>If you suspect a Scam please report it to the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16477</th>\n",
       "      <td>23861</td>\n",
       "      <td>68813</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>24-03-2020</td>\n",
       "      <td>@acgrayling Despite Covid-19 pandemic deaths a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "id": "87-M12F9Mbk-",
    "outputId": "cd61072b-9812-4598-a1dc-5335e41681bf",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:08:55.387368Z",
     "start_time": "2025-05-18T13:08:55.373732Z"
    }
   },
   "source": [
    "df.isnull().value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName  ScreenName  Location  TweetAt  OriginalTweet  Sentiment\n",
       "False     False       False     False    False          False        33444\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tzt27tfjUpq"
   },
   "source": [
    "Разделите данные на обучающие и тестовые в соотношении 7 : 3 и\n",
    "\n",
    "укажите `random_state=0`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xSLOA9tIj9Z6",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:08:56.237308Z",
     "start_time": "2025-05-18T13:08:55.550133Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(\n",
    "    df,\n",
    "    test_size = 0.3,\n",
    "    random_state = 0\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9RrPUsJlL60"
   },
   "source": [
    "## Задание 2 Токенизация (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Dz_b7Xopc_R"
   },
   "source": [
    "Постройте словарь на основе обучающей выборки и посчитайте количество встреч каждого токена с использованием самой простой токенизации - деления текстов по пробельным символам и приведения токенов в нижний регистр."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFr67WOJphny",
    "outputId": "a7cbfccd-8aed-403b-d2ec-9c2cf41c3216",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:08:56.484416Z",
     "start_time": "2025-05-18T13:08:56.394781Z"
    }
   },
   "source": [
    "bag=[]\n",
    "for i in train['OriginalTweet']:\n",
    "    lowi = i.lower()\n",
    "    tokens = lowi.split()\n",
    "    for token in tokens:\n",
    "        bag.append(token)\n",
    "\n",
    "bag[0:30]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['why',\n",
       " 'we',\n",
       " 'still',\n",
       " 'want',\n",
       " 'to',\n",
       " 'buy',\n",
       " 'so',\n",
       " 'much',\n",
       " 'stuff',\n",
       " 'during',\n",
       " 'quarantine',\n",
       " 'https://t.co/1m881cwfuv',\n",
       " '#shopping',\n",
       " '#covid_19',\n",
       " '#online',\n",
       " 'with',\n",
       " 'driving',\n",
       " 'even',\n",
       " 'more',\n",
       " 'usage',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'strategy',\n",
       " 'is',\n",
       " 'critical',\n",
       " 'now',\n",
       " 'more',\n",
       " 'then',\n",
       " 'ever',\n",
       " 'luckily']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pe0h2Jqkpnao"
   },
   "source": [
    "Какой размер словаря получился?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umyENA7EpokD",
    "outputId": "e830fbb6-e687-4f6f-9ec0-9164ab5abb12",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:08:56.579616Z",
     "start_time": "2025-05-18T13:08:56.572993Z"
    }
   },
   "source": [
    "len(bag)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "754630"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d2G1Z-Qpqkd"
   },
   "source": [
    "Выведите 10 самых популярных токенов с количеством встреч каждого из них. Объясните, почему именно эти токены в топе."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Impi32a_pssg",
    "outputId": "4f9be283-978c-4b89-a61b-9f699acc2c07",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:08:56.778816Z",
     "start_time": "2025-05-18T13:08:56.649595Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "freq = Counter(bag)\n",
    "top10 = freq.most_common(10)\n",
    "top10\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 26815),\n",
       " ('to', 23373),\n",
       " ('and', 14684),\n",
       " ('of', 13012),\n",
       " ('a', 11737),\n",
       " ('in', 11198),\n",
       " ('for', 8566),\n",
       " ('#coronavirus', 8223),\n",
       " ('is', 7383),\n",
       " ('are', 7050)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtuJCD0ApuFd"
   },
   "source": [
    "**Ответ:** # Мы видим слова, которые наиболее часто используются в речи и предложениях, особенно в английском яызке. Например, артикли the и a встречаются повсеместно по всему языку, хотя и не несут значимой для анализа (чаще всего) пользы.\n",
    "\n",
    "Из интересного #coronavirus часто встречался в контексте. Даже чаще, чем is и are. Это может говорить о том, что датасет вероятно с ковидных времен, когда об этом говорили постоянно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7DTQDkWsVYp"
   },
   "source": [
    "Удалите стоп-слова из словаря и выведите новый топ-10 токенов (и количество встреч) по популярности.  Что можно сказать  о нем?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "8csSAdgTsnFx",
    "outputId": "38e0f016-c02e-449b-cba2-4390f8d68668",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:08:58.412383Z",
     "start_time": "2025-05-18T13:08:56.857640Z"
    }
   },
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "pd_bag = pd.Series(bag)\n",
    "fbag = pd_bag[~pd_bag.isin(stopwords.words())]\n",
    "\n",
    "fbag.value_counts().head(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#coronavirus    8223\n",
       "prices          3891\n",
       "food            3820\n",
       "grocery         3469\n",
       "supermarket     3288\n",
       "covid-19        3173\n",
       "store           3155\n",
       "#covid19        2471\n",
       "&amp;           2314\n",
       "consumer        2245\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZH0x2Lzs-Dh"
   },
   "source": [
    "**Ответ:**  Ну как я и подозревал, все оказалось словами-филлерами в предыдущем примере.  В общем, по топ10 явно видно, что бушевал ковид, люди жаловались на цены, еду, продукты и супермаркеты.\n",
    "\n",
    "НО! Как-то в примеры просочился амперсанд, это не очень хороший знак(в плане образно, а не фигурально). Либо твиттер его использует при индексации, либо люди любят часто его писать. Формально, наверное, это можно считать stop-word'ом... иииии.. Вероятно, его можно выскрести с помощью хорошего токенайзера с помощью nltk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKSGRyI-uor0"
   },
   "source": [
    "Также выведите 20 самых непопулярных слов (если самых непопулярных слов больше, выведите любые 20 из них) Почему эти токены непопулярны, требуется ли как-то дополнительно работать с ними?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "moArbwfvun9t",
    "outputId": "9c4f73c1-f155-4401-af5c-60f138c78675",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:08:58.560776Z",
     "start_time": "2025-05-18T13:08:58.484994Z"
    }
   },
   "source": [
    "fbag.value_counts().tail(20)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50kg                       1\n",
       "466                        1\n",
       "pmt                        1\n",
       "acres                      1\n",
       "cucumber                   1\n",
       "https://t.co/x69jqbisox    1\n",
       "#springcleaning            1\n",
       "587-4272                   1\n",
       "massive.                   1\n",
       "https://t.co/l8jnzxjgwo    1\n",
       "readiness,                 1\n",
       "kick-in                    1\n",
       "(covid-19,                 1\n",
       "impacts)                   1\n",
       "https://t.co/wa7kcdwqea    1\n",
       "@linkedin                  1\n",
       "clare                      1\n",
       "connors                    1\n",
       "levins                     1\n",
       "https://t.co/7j2y3rsld9    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRp3J1gQunlR"
   },
   "source": [
    "**Ответ:** Внимание! На горизонте всякий мусор. Мы видим кучу ссылок, странных штук что слепились... А еще страну в Азии под названием Бурма. Слышали когда-нибудь об этом? Я тоже.. нет.. Но вот огурцы похоже твиттеряне не долюбливают.\n",
    "\n",
    "По-хорошему, нужно почистить от всяких ссылок неприятных массив данных. А еще ВОСПОЛЬЗОВАТЬСЯ НОРМАЛЬНЫМ ТОКЕНАЙЗЕРОМ, чтобы не было таких (кейсов?\"!)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wx9LQOSPzvjV"
   },
   "source": [
    "Теперь воспользуемся токенайзером получше - TweetTokenizer из библиотеки nltk. Примените его и посмотрите на топ-10 популярных слов. Чем он отличается от топа, который получался раньше? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "2G1UkyVxzvFY",
    "outputId": "ef4ac04b-6576-4acb-e9c3-cb901af0c796",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:09:00.507086Z",
     "start_time": "2025-05-18T13:08:58.660336Z"
    }
   },
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "tokens = fbag.apply(tokenizer.tokenize).explode()\n",
    "# nt = tokens[~tokens.isin(stopwords.words())]\n",
    "tokens.value_counts().head(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".               24418\n",
       ",               17571\n",
       "?                9524\n",
       "#coronavirus     8808\n",
       "â                7415\n",
       "                7311\n",
       "19               7167\n",
       "-                6643\n",
       "covid            6253\n",
       "prices           4601\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50eVUnJN1Zxl"
   },
   "source": [
    "**Ответ:** Надо поубирать стопслова и пунктуацию. У нас появились всякие точки, запятые, и прочее.. Потому что токенайзером воспользовались, а не просто поделили по пробелам\n",
    "\n",
    "Из плюсов, видно как ушли всякие **подобные?%;№\"! !.штуковины и амперсанды!!!!**\n",
    "\n",
    "но ссылки остались:(((\n",
    "\n",
    "Для меня загадка – число 19 (А СТОП КОВИД-19 ЖЕ, забыли),\n",
    "а еще \"â\" (видимо какой-то испанский прикол)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "c4LLJF4agXXP",
    "outputId": "c9029115-c8c2-4a12-bb48-d3a828384b3c",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:09:00.830496Z",
     "start_time": "2025-05-18T13:09:00.764603Z"
    }
   },
   "source": [
    "tokens.value_counts().tail(20)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@gordongchang              1\n",
       "logarithmic                1\n",
       "#foodretail                1\n",
       "non-log                    1\n",
       "improveã                   1\n",
       "https://t.co/aacxqg5sej    1\n",
       "rebooked                   1\n",
       "can't-miss                 1\n",
       "https://t.co/8xikga3rel    1\n",
       "@awgcorporate              1\n",
       "https://t.co/fglsnpoj4k    1\n",
       "https://t.co/dj8jvtzrs7    1\n",
       "https://t.co/cuu8ff09pg    1\n",
       "https://t.co/gyogjmwo68    1\n",
       "shoukd                     1\n",
       "https://t.co/vpgmpxrgba    1\n",
       "distsnce                   1\n",
       "resteraunts                1\n",
       "crams                      1\n",
       "https://t.co/7j2y3rsld9    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gqQgiMs11bs"
   },
   "source": [
    "Удалите из словаря стоп-слова и пунктуацию, посмотрите на новый топ-10 слов с количеством встреч, есть ли теперь в нем что-то не похожее на слова?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "0yHWdFrp0Mup",
    "outputId": "48005148-2b2b-4f9e-c91d-b8d9ecd6383b",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:09:01.121374Z",
     "start_time": "2025-05-18T13:09:01.006867Z"
    }
   },
   "source": [
    "from string import punctuation\n",
    "\n",
    "# punctuation?\n",
    "\n",
    "nt = tokens[~tokens.isin(list(punctuation))]\n",
    "nt = nt[~nt.isin(stopwords.words())]\n",
    "\n",
    "nt.value_counts().head(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#coronavirus    8808\n",
       "â               7415\n",
       "               7311\n",
       "19              7167\n",
       "covid           6253\n",
       "prices          4601\n",
       "               4372\n",
       "food            4367\n",
       "store           3877\n",
       "supermarket     3805\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZJqXELP_Yxy"
   },
   "source": [
    "**Ответ:** Да, мы видим \"\" или  \"  \" и все еще загадочный \"â\". Согласен, достаточно немногословно. Вероятно какие-то символы для оформления, либо особенности оформления."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzXjMsSB_kXB"
   },
   "source": [
    "Скорее всего в некоторых топах были неотображаемые символы или отдельные буквы не латинского алфавита. Уберем их: удалите из словаря токены из одного символа, позиция которого в таблице Unicode 128 и более (`ord(x) >= 128`)\n",
    "\n",
    "Выведите топ-10 самых популярных и топ-20 непопулярных слов. Чем полученные топы отличаются от итоговых топов, полученных при использовании токенизации по пробелам? Что теперь лучше, а что хуже?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "1695hlkS_1-J",
    "outputId": "d52ffe15-41a4-4f5d-d999-10cb4eb61668",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:09:01.380282Z",
     "start_time": "2025-05-18T13:09:01.293070Z"
    }
   },
   "source": [
    "nt = nt[~nt.apply(lambda x: len(x) == 1 and ord(x) >= 128)]\n",
    "nt.value_counts().head(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#coronavirus    8808\n",
       "19              7167\n",
       "covid           6253\n",
       "prices          4601\n",
       "food            4367\n",
       "store           3877\n",
       "supermarket     3805\n",
       "grocery         3523\n",
       "#covid19        2589\n",
       "consumer        2340\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "Iinre_6Wmvu6",
    "outputId": "4986d5ff-168d-4593-d637-9d03bf5c2347",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:09:01.584084Z",
     "start_time": "2025-05-18T13:09:01.540145Z"
    }
   },
   "source": [
    "nt.value_counts().tail(20)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#nevada                    1\n",
       "@frickindistant            1\n",
       "synopsis                   1\n",
       "equation                   1\n",
       "hendrickson                1\n",
       "https://t.co/hq23xalxjo    1\n",
       "https://t.co/vy6hr3ui76    1\n",
       "biso                       1\n",
       "@robertgordonuni           1\n",
       "https://t.co/tfnetiq3uq    1\n",
       "https://t.co/njh8dbwdxc    1\n",
       "power-up                   1\n",
       "callaway                   1\n",
       "@krcg13                    1\n",
       "https://t.co/shevekhipn    1\n",
       "michiganders               1\n",
       "whitless                   1\n",
       "@aifytheresa               1\n",
       "https://t.co/etvxjkjooa    1\n",
       "https://t.co/7j2y3rsld9    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzjHAKIlDvc6"
   },
   "source": [
    "**Ответ:** Ну слушайте, это уже очень хорошо, мы избавились от всякого мусора и остались удобоваримые приятные вещи. Все еще сильно засоряют хештеги пространство. Отличаются от пробельных тем, что нет всякого мусора ни в самих токенах, ни отдельно. Это приятно, с этим можно работать.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcDf9_6HB2zm"
   },
   "source": [
    "Выведите топ-10 популярных хештегов (токены, первые символы которых - #) с количеством встреч. Что можно сказать о них?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "zk4fygCUBw3l",
    "outputId": "3aad18bb-8d98-4853-bd72-38b392831465",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:09:01.789883Z",
     "start_time": "2025-05-18T13:09:01.738996Z"
    }
   },
   "source": [
    "nt[nt.apply(lambda x: x[0] == '#')].value_counts().head(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#coronavirus            8808\n",
       "#covid19                2589\n",
       "#covid_19               1734\n",
       "#covid2019               946\n",
       "#toiletpaper             744\n",
       "#covid                   641\n",
       "#socialdistancing        465\n",
       "#coronacrisis            448\n",
       "#pandemic                257\n",
       "#coronaviruspandemic     249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6NeNWBkDxM7"
   },
   "source": [
    "**Ответ:** #toiletpaper единственный хештег, косвенный к упоминанию ковида. многое говорит о нашем обществе...............\n",
    "\n",
    "Мы видим, что в те времена царил ковид и самыми главными темами было обсуждение и упомянание ковида."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLYBg7caD5GA"
   },
   "source": [
    "То же самое проделайте для ссылок на сайт https://t.co Сравнима ли популярность ссылок с популярностью хештегов? Будет ли информация о ссылке на конкретную страницу полезна?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "MXbm1oeaCK9S",
    "outputId": "93e0b8d9-fc2e-4fef-fcdb-d5f7db1ff104",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:09:02.011363Z",
     "start_time": "2025-05-18T13:09:01.964547Z"
    }
   },
   "source": [
    "nt[nt.apply(lambda x: x.startswith('https://t.co'))].value_counts().head(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "https://t.co/oxa7swtond    5\n",
       "https://t.co/gp3eusapl8    4\n",
       "https://t.co/kuwipf1kqw    3\n",
       "https://t.co/bylqxrjmnt    3\n",
       "https://t.co/wuieefsnoj    3\n",
       "https://t.co/zjnrx6dkkn    3\n",
       "https://t.co/wrlhyzizaa    3\n",
       "https://t.co/g63rp042ho    3\n",
       "https://t.co/e2znxajpre    3\n",
       "https://t.co/catkegayoy    3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "at6lRYZ8A07N"
   },
   "source": [
    "**Ответ:** # Очевидно, популярность у таких штук будет ощутимо меньше. Это логично, ведь все ссылки уникальны. Редко, когда будут делиться чем-то одним и тем же.\n",
    "Для обучения они нам не нужны и бесполезны. Убираем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOGdUU1kBU1D"
   },
   "source": [
    "Используем опыт предыдущих экспериментов и напишем собственный токенайзер, улучшив TweetTokenizer. Функция tokenize должна:\n",
    "\n",
    "\n",
    "\n",
    "*   Привести текст в нижний регистр\n",
    "*   Применить TweetTokenizer для  выделения токенов\n",
    "*   Удалить стоп-слова, пунктуацию, токены из одного символа с позицией в таблице Unicode 128 и более,  ссылки на t.co\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ctEsB6xkFrrK",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:09:02.171414Z",
     "start_time": "2025-05-18T13:09:02.168967Z"
    }
   },
   "source": [
    "def custom_tokenizer(text):\n",
    "  tokens = pd.Series(text.lower())\n",
    "  tokens = tokens.apply(tokenizer.tokenize).explode()\n",
    "\n",
    "  nt = tokens[~tokens.isin(list(punctuation))]\n",
    "  nt = nt[~nt.isin(stopwords.words())]\n",
    "\n",
    "  nt = nt[~nt.apply(lambda x: len(x) == 1 and ord(x) >= 128)]\n",
    "\n",
    "  nt = nt[~(nt.apply(lambda x: x.startswith('https://t.co')))]\n",
    "\n",
    "  tokens = nt.to_list()\n",
    "  return tokens\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XwbgtYkJGYym",
    "outputId": "d76cc27a-0e72-4bf6-9686-c2ede863659f",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:09:02.316290Z",
     "start_time": "2025-05-18T13:09:02.308953Z"
    }
   },
   "source": [
    "custom_tokenizer('This is sample text!!!! @Sample_text I, \\x92\\x92 https://t.co/sample  #sampletext')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample', 'text', '@sample_text', '#sampletext']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wURVABmXHk97"
   },
   "source": [
    "## Задание 3 Векторизация текстов (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H44iXkoHIQfN"
   },
   "source": [
    "Обучите CountVectorizer с использованием custom_tokenizer в качестве токенайзера. Как размер полученного словаря соотносится с размером изначального словаря из начала задания 2?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHn_limQl3BI",
    "outputId": "96ce228b-4701-4de3-f0d5-99598578cbef",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:10:10.398209Z",
     "start_time": "2025-05-18T13:09:02.434529Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(tokenizer = custom_tokenizer)\n",
    "cv.fit(train['OriginalTweet'])\n",
    "\n",
    "print(len(cv.vocabulary_))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44498\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsfmaSGoItUm"
   },
   "source": [
    "**Ответ:** слов стало гораздо меньше потому что мы убрали с помощью токенайзера весь мусор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lm6UHNmqKZT0"
   },
   "source": [
    "Посмотрим на какой-нибудь конкретный твитт:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJVjjfqOJh8m",
    "outputId": "fa67516c-1253-439e-b636-bc412c1b6bbb",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:10:10.489660Z",
     "start_time": "2025-05-18T13:10:10.484590Z"
    }
   },
   "source": [
    "ind = 9023\n",
    "train.iloc[ind]['OriginalTweet'], train.iloc[ind]['Sentiment']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Nice one @SkyNews lets not panic but show ppl in france queueing for food!!! #CoronavirusOutbreak #COVID2019 brainless!! Ffs',\n",
       " np.int64(0))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBMIHBI5KdaS"
   },
   "source": [
    "Автор твитта не доволен ситуацией с едой во Франции и текст имеет резко негативную окраску.\n",
    "\n",
    "Примените обученный CountVectorizer для векторизации данного текста, и попытайтесь определить самый важный токен и самый неважный токен (токен, компонента которого в векторе максимальна/минимальна, без учета 0). Хорошо ли они определились, почему?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NcAllaEKsJj",
    "outputId": "b9a24574-1d89-43a5-98ea-aabb0fb3be0e",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:14:39.746186Z",
     "start_time": "2025-05-18T13:14:39.689383Z"
    }
   },
   "source": [
    "tweet = train.iloc[ind]['OriginalTweet']\n",
    "vec = cv.transform([tweet]).toarray().flatten()\n",
    "features = cv.get_feature_names_out()\n",
    "idx = np.nonzero(vec)[0]\n",
    "\n",
    "max_idx = idx[vec[idx].argmax()]\n",
    "min_idx = idx[vec[idx].argmin()]\n",
    "\n",
    "print(f\"{features[max_idx]} – важный (частота {vec[max_idx]})\")\n",
    "print(f\"{features[min_idx]} – неважный (частота {vec[min_idx]})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#coronavirusoutbreak – важный (частота 1)\n",
      "#coronavirusoutbreak – неважный (частота 1)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpEsl1k_NF4T"
   },
   "source": [
    "**Ответ:** Ну похоже наш countvectorizer бесполезный.. Все по единичке (я проверил)... BoW смотрит же на повторяемосьь.. Значит надо иначе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4DsEQpLO3J6"
   },
   "source": [
    "Теперь примените TfidfVectorizer и  определите самый важный/неважный токены. Хорошо ли определились, почему?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhm3G_kOITir",
    "outputId": "d9a5afc1-4a36-4a1c-eefd-20c0961c547e",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:15:49.842719Z",
     "start_time": "2025-05-18T13:14:43.290965Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer = custom_tokenizer)\n",
    "tfidf.fit(train['OriginalTweet'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(tokenizer=<function custom_tokenizer at 0x144b4e340>)"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(tokenizer=&lt;function custom_tokenizer at 0x144b4e340&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(tokenizer=&lt;function custom_tokenizer at 0x144b4e340&gt;)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "uSNzdK3ENGB3",
    "outputId": "f6ddc957-90c5-4bf9-f03c-e60edd2059ff",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:15:49.980741Z",
     "start_time": "2025-05-18T13:15:49.945876Z"
    }
   },
   "source": [
    "tweet = train.iloc[ind]['OriginalTweet']\n",
    "vec = tfidf.transform([tweet]).toarray().flatten()\n",
    "features = tfidf.get_feature_names_out()\n",
    "idx = np.nonzero(vec)[0]\n",
    "\n",
    "max_idx = idx[vec[idx].argmax()]\n",
    "min_idx = idx[vec[idx].argmin()]\n",
    "\n",
    "print(f\"{features[max_idx]} – важный (частота {vec[max_idx]})\")\n",
    "print(f\"{features[min_idx]} – неважный (частота {vec[min_idx]})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brainless – важный (частота 0.39201120274014334)\n",
      "food – неважный (частота 0.1148258797042418)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYao_UhqQADm"
   },
   "source": [
    "**Ответ:** Здесь мы уже видим явное определение. Метод TF IDF работает лучше потому что использует другую стратегию. Он учитывает значимость слов глобально, в то время как countvectorizer просто считает, есть ли слово (1 и 0), вообще не задумываясь о важности и контексте\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGRJPqfWSesQ"
   },
   "source": [
    "Найдите какой-нибудь положительно окрашенный твитт, где TfidfVectorizer хорошо (полезно для определения окраски) выделяет важный токен, поясните пример.\n",
    "\n",
    "*Подсказка:* явно положительные твитты можно искать при помощи положительных слов (good, great, amazing и т. д.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "qv2dhfcT0nl7",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:24:26.876606Z",
     "start_time": "2025-05-18T13:24:26.860683Z"
    }
   },
   "source": [
    "tweetPositive = train['OriginalTweet'][23284]"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bRbQ2CHiSuJI",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:24:27.978007Z",
     "start_time": "2025-05-18T13:24:27.948496Z"
    }
   },
   "source": [
    "train[train['OriginalTweet'].apply(lambda x: 'enjoy' in x) & (train['Sentiment'] == 1)]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       UserName  ScreenName                        Location     TweetAt  \\\n",
       "20526     28843       73795    ÃÂT: 51.4761159,-2.5612165  29-03-2020   \n",
       "21131     29571       74523           Wales, United Kingdom  01-04-2020   \n",
       "15590     22757       67709          Riyadh- London-Reading  24-03-2020   \n",
       "282        4143       49095                         Unknown  16-03-2020   \n",
       "20788     29157       74109                  San Rafael, CA  31-03-2020   \n",
       "18368     26144       71096                         Unknown  25-03-2020   \n",
       "18229     25978       70930                    Highland, UT  25-03-2020   \n",
       "32073     43255       88207                          Brasil  13-04-2020   \n",
       "4399       9147       54099                         Unknown  18-03-2020   \n",
       "17351     24909       69861                         Unknown  25-03-2020   \n",
       "13832     20591       65543                           India  22-03-2020   \n",
       "23284     32250       77202               Sydney, Australia  04-04-2020   \n",
       "22123     30824       75776                 Los Angeles, CA  02-04-2020   \n",
       "949        4945       49897                         Unknown  17-03-2020   \n",
       "30679     41532       86484                Philadelphia, PA  11-04-2020   \n",
       "15285     22407       67359                 Toronto, Canada  23-03-2020   \n",
       "1892       6107       51059                         Unknown  17-03-2020   \n",
       "30862     41765       86717        Peterborough, Ontario ??  11-04-2020   \n",
       "22671     31503       76455                           India  03-04-2020   \n",
       "16510     23903       68855              West Hollywood, CA  24-03-2020   \n",
       "3306       7802       52754               Bergen County, NJ  18-03-2020   \n",
       "19935     28102       73054                       Australia  26-03-2020   \n",
       "3802       8413       53365               San Francisco, CA  18-03-2020   \n",
       "31885     43019       87971         England, United Kingdom  12-04-2020   \n",
       "8758      14440       59392                   New York, USA  20-03-2020   \n",
       "5004       9886       54838                         Unknown  19-03-2020   \n",
       "33194     44641       89593             Melbourne, Victoria  13-04-2020   \n",
       "23275     32237       77189                           India  04-04-2020   \n",
       "29826     40418       85370  North Vancouver & South Surrey  09-04-2020   \n",
       "19090     27033       71985                    Warwickshire  25-03-2020   \n",
       "12540     19001       63953                         Unknown  22-03-2020   \n",
       "21301     29780       74732             Canvey Island, East  01-04-2020   \n",
       "27755     37821       82773                     Amherst, MA  08-04-2020   \n",
       "32944     44315       89267             Manchester, England  13-04-2020   \n",
       "18970     26894       71846                         Unknown  25-03-2020   \n",
       "23392     32378       77330                     Houston, TX  04-04-2020   \n",
       "22853     31723       76675            ? ? ? ? ??????????-!  04-04-2020   \n",
       "7040      12360       57312                Hamburg, Germany  19-03-2020   \n",
       "24671     33994       78946         Earth, Milky Way Galaxy  06-04-2020   \n",
       "18302     26068       71020                 California, USA  25-03-2020   \n",
       "15546     22709       67661                         Unknown  24-03-2020   \n",
       "211        4055       49007                         Toronto  16-03-2020   \n",
       "32736     44065       89017                         Unknown  13-04-2020   \n",
       "10216     16200       61152                          USA/EU  21-03-2020   \n",
       "14606     21551       66503                         Unknown  23-03-2020   \n",
       "15198     22300       67252                   San Francisco  23-03-2020   \n",
       "5580      10576       55528                  Ngong, Kenya??  19-03-2020   \n",
       "7719      13180       58132                St Augustine, FL  20-03-2020   \n",
       "25819     35422       80374                      Euphoria .  07-04-2020   \n",
       "\n",
       "                                           OriginalTweet  Sentiment  \n",
       "20526  I'm getting pretty fucking sick of celebs tell...          1  \n",
       "21131  Check out our recent blog post on Coronavirus,...          1  \n",
       "15590  @Harrods Your store is the best to me, and it ...          1  \n",
       "282    This guy is taking the whole #coronavirus in h...          1  \n",
       "20788  \"As we practice social distancing, stock food ...          1  \n",
       "18368  @Antcon7062 Seriously ? what is closing off li...          1  \n",
       "18229  Ya'll ever use so much hand sanitizer, that yo...          1  \n",
       "32073  Good morning on We hope you re enjoying your w...          1  \n",
       "4399   Please avoid unnecessary movement and enjoy th...          1  \n",
       "17351  @katiecouric Stuck at home without Covid-19 te...          1  \n",
       "13832  Thanks Govt for the beautiful step to lockdown...          1  \n",
       "23284  Some Australian farmers are enjoying five-fold...          1  \n",
       "22123  COVID-19: Packaged foods and snack brands enjo...          1  \n",
       "949    Y'all after this, no one should ever look down...          1  \n",
       "30679  Whether you re in Philadelphia or another part...          1  \n",
       "15285  Please enjoy Tuesday's #COVID?19 cartoon in @T...          1  \n",
       "1892   All those people now selling sanitizers at exo...          1  \n",
       "30862  #togetherapart 1/2\\r\\r\\n\\r\\r\\nI have never enj...          1  \n",
       "22671  Oil importing countries, like India, can enjoy...          1  \n",
       "16510  Actually enjoying this social distancing. The ...          1  \n",
       "3306   Supporting our local restaurants *and* saying ...          1  \n",
       "19935  Online Delivery Info - we understand that ther...          1  \n",
       "3802   The #weirdstreamathon is on! Join us to help r...          1  \n",
       "31885  I launched online networking with @Collabor8UK...          1  \n",
       "8758   Got a new posted on my YouTube channel, please...          1  \n",
       "5004   Good morning everyone, except you panic buyers...          1  \n",
       "33194  Really enjoying the look on faces of people wh...          1  \n",
       "23275  Oil importing countries, like India, can enjoy...          1  \n",
       "29826  Here are our South Surrey retail store long we...          1  \n",
       "19090  With everything uncertain in the world at the ...          1  \n",
       "12540  First day working as a checkout girl today.\\r\\...          1  \n",
       "21301  IÃÂd like thank ALL of the supermarket chain...          1  \n",
       "27755  How to enjoy online shopping without supportin...          1  \n",
       "32944  @WillowWyse @talkRADIO @JuliaHB1 @obbsie Ultim...          1  \n",
       "18970  What's a better way to enjoy the apocalypse th...          1  \n",
       "23392  Amid all the panic and worry, allow yourself t...          1  \n",
       "22853  Japanese style is enjoying spurt in popularity...          1  \n",
       "7040   Just bought all the pesto and canned tomatoes ...          1  \n",
       "24671  Like for low-economic-incomed people, now is t...          1  \n",
       "18302  @sprint ... canÃÂt enjoy quarantine without ...          1  \n",
       "15546  Stay home and help fight #coronavirus! Since #...          1  \n",
       "211    For a long time we could only dream of what Re...          1  \n",
       "32736     Do you enjoy your coffee iced   LINK TO BUY 19          1  \n",
       "10216  Sometimes itÃÂs hard to describe why I enjoy...          1  \n",
       "14606  We like grocery shopping because we enjoy pick...          1  \n",
       "15198  @PeterEgan6 Hi Peter, lovely to see your beaut...          1  \n",
       "5580   Alert: Largest wholesale and retail Ongata Ron...          1  \n",
       "7719   #coronavirus  was unleashed by big oil so we c...          1  \n",
       "25819  Lol anything in with ice I m sold You re getti...          1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20526</th>\n",
       "      <td>28843</td>\n",
       "      <td>73795</td>\n",
       "      <td>ÃÂT: 51.4761159,-2.5612165</td>\n",
       "      <td>29-03-2020</td>\n",
       "      <td>I'm getting pretty fucking sick of celebs tell...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21131</th>\n",
       "      <td>29571</td>\n",
       "      <td>74523</td>\n",
       "      <td>Wales, United Kingdom</td>\n",
       "      <td>01-04-2020</td>\n",
       "      <td>Check out our recent blog post on Coronavirus,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15590</th>\n",
       "      <td>22757</td>\n",
       "      <td>67709</td>\n",
       "      <td>Riyadh- London-Reading</td>\n",
       "      <td>24-03-2020</td>\n",
       "      <td>@Harrods Your store is the best to me, and it ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>4143</td>\n",
       "      <td>49095</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>This guy is taking the whole #coronavirus in h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20788</th>\n",
       "      <td>29157</td>\n",
       "      <td>74109</td>\n",
       "      <td>San Rafael, CA</td>\n",
       "      <td>31-03-2020</td>\n",
       "      <td>\"As we practice social distancing, stock food ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18368</th>\n",
       "      <td>26144</td>\n",
       "      <td>71096</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>25-03-2020</td>\n",
       "      <td>@Antcon7062 Seriously ? what is closing off li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18229</th>\n",
       "      <td>25978</td>\n",
       "      <td>70930</td>\n",
       "      <td>Highland, UT</td>\n",
       "      <td>25-03-2020</td>\n",
       "      <td>Ya'll ever use so much hand sanitizer, that yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32073</th>\n",
       "      <td>43255</td>\n",
       "      <td>88207</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>Good morning on We hope you re enjoying your w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>9147</td>\n",
       "      <td>54099</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>18-03-2020</td>\n",
       "      <td>Please avoid unnecessary movement and enjoy th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17351</th>\n",
       "      <td>24909</td>\n",
       "      <td>69861</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>25-03-2020</td>\n",
       "      <td>@katiecouric Stuck at home without Covid-19 te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13832</th>\n",
       "      <td>20591</td>\n",
       "      <td>65543</td>\n",
       "      <td>India</td>\n",
       "      <td>22-03-2020</td>\n",
       "      <td>Thanks Govt for the beautiful step to lockdown...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23284</th>\n",
       "      <td>32250</td>\n",
       "      <td>77202</td>\n",
       "      <td>Sydney, Australia</td>\n",
       "      <td>04-04-2020</td>\n",
       "      <td>Some Australian farmers are enjoying five-fold...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22123</th>\n",
       "      <td>30824</td>\n",
       "      <td>75776</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>02-04-2020</td>\n",
       "      <td>COVID-19: Packaged foods and snack brands enjo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>4945</td>\n",
       "      <td>49897</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>17-03-2020</td>\n",
       "      <td>Y'all after this, no one should ever look down...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30679</th>\n",
       "      <td>41532</td>\n",
       "      <td>86484</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>11-04-2020</td>\n",
       "      <td>Whether you re in Philadelphia or another part...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15285</th>\n",
       "      <td>22407</td>\n",
       "      <td>67359</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>23-03-2020</td>\n",
       "      <td>Please enjoy Tuesday's #COVID?19 cartoon in @T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>6107</td>\n",
       "      <td>51059</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>17-03-2020</td>\n",
       "      <td>All those people now selling sanitizers at exo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30862</th>\n",
       "      <td>41765</td>\n",
       "      <td>86717</td>\n",
       "      <td>Peterborough, Ontario ??</td>\n",
       "      <td>11-04-2020</td>\n",
       "      <td>#togetherapart 1/2\\r\\r\\n\\r\\r\\nI have never enj...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22671</th>\n",
       "      <td>31503</td>\n",
       "      <td>76455</td>\n",
       "      <td>India</td>\n",
       "      <td>03-04-2020</td>\n",
       "      <td>Oil importing countries, like India, can enjoy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16510</th>\n",
       "      <td>23903</td>\n",
       "      <td>68855</td>\n",
       "      <td>West Hollywood, CA</td>\n",
       "      <td>24-03-2020</td>\n",
       "      <td>Actually enjoying this social distancing. The ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>7802</td>\n",
       "      <td>52754</td>\n",
       "      <td>Bergen County, NJ</td>\n",
       "      <td>18-03-2020</td>\n",
       "      <td>Supporting our local restaurants *and* saying ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19935</th>\n",
       "      <td>28102</td>\n",
       "      <td>73054</td>\n",
       "      <td>Australia</td>\n",
       "      <td>26-03-2020</td>\n",
       "      <td>Online Delivery Info - we understand that ther...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>8413</td>\n",
       "      <td>53365</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>18-03-2020</td>\n",
       "      <td>The #weirdstreamathon is on! Join us to help r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31885</th>\n",
       "      <td>43019</td>\n",
       "      <td>87971</td>\n",
       "      <td>England, United Kingdom</td>\n",
       "      <td>12-04-2020</td>\n",
       "      <td>I launched online networking with @Collabor8UK...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>14440</td>\n",
       "      <td>59392</td>\n",
       "      <td>New York, USA</td>\n",
       "      <td>20-03-2020</td>\n",
       "      <td>Got a new posted on my YouTube channel, please...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>9886</td>\n",
       "      <td>54838</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>19-03-2020</td>\n",
       "      <td>Good morning everyone, except you panic buyers...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33194</th>\n",
       "      <td>44641</td>\n",
       "      <td>89593</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>Really enjoying the look on faces of people wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23275</th>\n",
       "      <td>32237</td>\n",
       "      <td>77189</td>\n",
       "      <td>India</td>\n",
       "      <td>04-04-2020</td>\n",
       "      <td>Oil importing countries, like India, can enjoy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29826</th>\n",
       "      <td>40418</td>\n",
       "      <td>85370</td>\n",
       "      <td>North Vancouver &amp; South Surrey</td>\n",
       "      <td>09-04-2020</td>\n",
       "      <td>Here are our South Surrey retail store long we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19090</th>\n",
       "      <td>27033</td>\n",
       "      <td>71985</td>\n",
       "      <td>Warwickshire</td>\n",
       "      <td>25-03-2020</td>\n",
       "      <td>With everything uncertain in the world at the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12540</th>\n",
       "      <td>19001</td>\n",
       "      <td>63953</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>22-03-2020</td>\n",
       "      <td>First day working as a checkout girl today.\\r\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21301</th>\n",
       "      <td>29780</td>\n",
       "      <td>74732</td>\n",
       "      <td>Canvey Island, East</td>\n",
       "      <td>01-04-2020</td>\n",
       "      <td>IÃÂd like thank ALL of the supermarket chain...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27755</th>\n",
       "      <td>37821</td>\n",
       "      <td>82773</td>\n",
       "      <td>Amherst, MA</td>\n",
       "      <td>08-04-2020</td>\n",
       "      <td>How to enjoy online shopping without supportin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32944</th>\n",
       "      <td>44315</td>\n",
       "      <td>89267</td>\n",
       "      <td>Manchester, England</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>@WillowWyse @talkRADIO @JuliaHB1 @obbsie Ultim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18970</th>\n",
       "      <td>26894</td>\n",
       "      <td>71846</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>25-03-2020</td>\n",
       "      <td>What's a better way to enjoy the apocalypse th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23392</th>\n",
       "      <td>32378</td>\n",
       "      <td>77330</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>04-04-2020</td>\n",
       "      <td>Amid all the panic and worry, allow yourself t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22853</th>\n",
       "      <td>31723</td>\n",
       "      <td>76675</td>\n",
       "      <td>? ? ? ? ??????????-!</td>\n",
       "      <td>04-04-2020</td>\n",
       "      <td>Japanese style is enjoying spurt in popularity...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>12360</td>\n",
       "      <td>57312</td>\n",
       "      <td>Hamburg, Germany</td>\n",
       "      <td>19-03-2020</td>\n",
       "      <td>Just bought all the pesto and canned tomatoes ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24671</th>\n",
       "      <td>33994</td>\n",
       "      <td>78946</td>\n",
       "      <td>Earth, Milky Way Galaxy</td>\n",
       "      <td>06-04-2020</td>\n",
       "      <td>Like for low-economic-incomed people, now is t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18302</th>\n",
       "      <td>26068</td>\n",
       "      <td>71020</td>\n",
       "      <td>California, USA</td>\n",
       "      <td>25-03-2020</td>\n",
       "      <td>@sprint ... canÃÂt enjoy quarantine without ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15546</th>\n",
       "      <td>22709</td>\n",
       "      <td>67661</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>24-03-2020</td>\n",
       "      <td>Stay home and help fight #coronavirus! Since #...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>4055</td>\n",
       "      <td>49007</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>For a long time we could only dream of what Re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32736</th>\n",
       "      <td>44065</td>\n",
       "      <td>89017</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>13-04-2020</td>\n",
       "      <td>Do you enjoy your coffee iced   LINK TO BUY 19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10216</th>\n",
       "      <td>16200</td>\n",
       "      <td>61152</td>\n",
       "      <td>USA/EU</td>\n",
       "      <td>21-03-2020</td>\n",
       "      <td>Sometimes itÃÂs hard to describe why I enjoy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14606</th>\n",
       "      <td>21551</td>\n",
       "      <td>66503</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>23-03-2020</td>\n",
       "      <td>We like grocery shopping because we enjoy pick...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15198</th>\n",
       "      <td>22300</td>\n",
       "      <td>67252</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>23-03-2020</td>\n",
       "      <td>@PeterEgan6 Hi Peter, lovely to see your beaut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5580</th>\n",
       "      <td>10576</td>\n",
       "      <td>55528</td>\n",
       "      <td>Ngong, Kenya??</td>\n",
       "      <td>19-03-2020</td>\n",
       "      <td>Alert: Largest wholesale and retail Ongata Ron...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7719</th>\n",
       "      <td>13180</td>\n",
       "      <td>58132</td>\n",
       "      <td>St Augustine, FL</td>\n",
       "      <td>20-03-2020</td>\n",
       "      <td>#coronavirus  was unleashed by big oil so we c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25819</th>\n",
       "      <td>35422</td>\n",
       "      <td>80374</td>\n",
       "      <td>Euphoria .</td>\n",
       "      <td>07-04-2020</td>\n",
       "      <td>Lol anything in with ice I m sold You re getti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jSjbKPCWk87K",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:24:30.758691Z",
     "start_time": "2025-05-18T13:24:30.754758Z"
    }
   },
   "source": [
    "tweetPositive"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Australian farmers are enjoying five-fold spikes in direct-to-consumer produce sales due to #coronavirus: https://t.co/8xFCpFe387 #buylocal'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hDFcH4iw-Ksg",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:24:33.458934Z",
     "start_time": "2025-05-18T13:24:33.422472Z"
    }
   },
   "source": [
    "\n",
    "vecpos = tfidf.transform([tweetPositive]).toarray().flatten()\n",
    "features = tfidf.get_feature_names_out()\n",
    "idxpos = np.nonzero(vecpos)[0]\n",
    "\n",
    "max_idx = idxpos[vecpos[idxpos].argmax()]\n",
    "min_idx = idxpos[vecpos[idxpos].argmin()]\n",
    "\n",
    "print(f\"{features[max_idx]} – важный (частота {vecpos[max_idx]})\")\n",
    "print(f\"{features[min_idx]} – неважный (частота {vecpos[min_idx]})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "five-fold – важный (частота 0.4314939277907398)\n",
      "#coronavirus – неважный (частота 0.08252535695941979)\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTv9ST2_U6NA"
   },
   "source": [
    "**Ответ:**  five-fold встречается в текстах достаточно редко, что выделяет этот твит срди других. #coronavirus, например, налборот есть везде, поэтому имеет низкую частоту TF IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVEuZm8BHms6"
   },
   "source": [
    "## Задание 4 Обучение первых моделей (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JADkO3sfXdOG"
   },
   "source": [
    "Примените оба векторайзера для получения матриц с признаками текстов.  Выделите целевую переменную."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:46:22.659262Z",
     "start_time": "2025-05-18T13:46:22.647096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = train['OriginalTweet']\n",
    "y_train = train['Sentiment']\n",
    "\n",
    "X_test = test['OriginalTweet']\n",
    "y_test = test['Sentiment']"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:48:47.406168Z",
     "start_time": "2025-05-18T13:46:35.380496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tfidf.fit(X_train)\n",
    "cv.fit(X_train)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(tokenizer=<function custom_tokenizer at 0x144b4e340>)"
      ],
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(tokenizer=&lt;function custom_tokenizer at 0x144b4e340&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(tokenizer=&lt;function custom_tokenizer at 0x144b4e340&gt;)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DguoiXhCX2oN",
    "outputId": "34d767f6-8870-4cef-8571-73623f4fb1e8",
    "ExecuteTime": {
     "end_time": "2025-05-18T13:55:50.589944Z",
     "start_time": "2025-05-18T13:52:35.201713Z"
    }
   },
   "source": [
    "X_tr_tfidf = tfidf.transform(X_train)\n",
    "X_te_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "X_tr_cv = cv.transform(X_train)\n",
    "X_te_cv = cv.transform(X_test)\n"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FX1KSOfYSx4"
   },
   "source": [
    "Обучите логистическую регрессию на векторах из обоих векторайзеров. Посчитайте долю правильных ответов на обучающих и тестовых данных. Какой векторайзер показал лучший результат? Что можно сказать о моделях?\n",
    "\n",
    "Используйте `sparse` матрицы (после векторизации), не превращайте их в `numpy.ndarray` или `pd.DataFrame` - может не хватить памяти."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-Tb3eh8UXJ6v",
    "ExecuteTime": {
     "end_time": "2025-05-18T14:20:14.475822Z",
     "start_time": "2025-05-18T14:20:14.222660Z"
    }
   },
   "source": [
    "print('tfidf')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classif = LogisticRegression(max_iter=10000)\n",
    "classif.fit(X_tr_tfidf, y_train)\n",
    "\n",
    "y_pred_train = classif.predict(X_tr_tfidf)\n",
    "y_pred_test = classif.predict(X_te_tfidf)\n",
    "\n",
    "print(f'train accurast: {accuracy_score(y_train, y_pred_train)}')\n",
    "print(f'test accuracy: {accuracy_score(y_test, y_pred_test)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf\n",
      "train accurast: 0.9044852627082444\n",
      "test accuracy: 0.8212078931632449\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:20:15.658835Z",
     "start_time": "2025-05-18T14:20:15.242975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('cv')\n",
    "classcv = LogisticRegression(max_iter=10000)\n",
    "classcv.fit(X_tr_cv, y_train)\n",
    "\n",
    "y_pred_train1 = classcv.predict(X_tr_cv)\n",
    "y_pred_test1 = classcv.predict(X_te_cv)\n",
    "\n",
    "print(f'train accurast: {accuracy_score(y_train, y_pred_train1)}')\n",
    "print(f'test accuracy: {accuracy_score(y_test, y_pred_test1)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv\n",
      "train accurast: 0.9739854762921828\n",
      "test accuracy: 0.8335658760215268\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8y_wO7rCmv7K"
   },
   "source": [
    "**Ответ:** CV лучше, чем tfidf в данном случае. работаем дальше с ним\n",
    "Также мы видим, что CV очень хорошо распознает train. Как бы ни хорошо, ни плохо\n",
    "Обе модели спользуют одну и ту же регуляризацию. В теории, если поиграться с рег., то можно получить и другие значнеия но меня уже все устраивает\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSOR1i3mjrys"
   },
   "source": [
    "## Задание 5 Стемминг (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6ONBWNPjuq-"
   },
   "source": [
    "Для уменьшения словаря можно использовать стемминг.\n",
    "\n",
    "Модифицируйте написанный токенайзер, добавив в него стемминг с использованием SnowballStemmer. Обучите Count- и Tfidf- векторайзеры. Как изменился размер словаря?"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:26:41.960865Z",
     "start_time": "2025-05-18T14:26:41.925859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oVfA2-iMkQBb",
    "ExecuteTime": {
     "end_time": "2025-05-18T14:33:43.169009Z",
     "start_time": "2025-05-18T14:33:43.161111Z"
    }
   },
   "source": [
    "def custom_stem_tokenizer(text):\n",
    "  tokens_cust = custom_tokenizer(text)\n",
    "  tokens = []\n",
    "  for i in tokens_cust:\n",
    "      tokens.append(stemmer.stem(i))\n",
    "  return tokens"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QmrjYtqnlPd",
    "outputId": "cd91291d-9676-4611-9fc4-28afaed58963",
    "ExecuteTime": {
     "end_time": "2025-05-18T14:33:45.027991Z",
     "start_time": "2025-05-18T14:33:45.007685Z"
    }
   },
   "source": "custom_stem_tokenizer('This is sample text!!!! @Sample_text I, \\x92\\x92 https://t.co/sample  #sampletext adding more words to check stemming')",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sampl', 'text', '@sample_text', '#sampletext', 'ad', 'word', 'check', 'stem']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zAvUTmaplzOS",
    "outputId": "566207fe-183b-4ed6-d333-f86f0cc9ae38",
    "ExecuteTime": {
     "end_time": "2025-05-18T14:39:49.056035Z",
     "start_time": "2025-05-18T14:34:58.716137Z"
    }
   },
   "source": [
    "cv = CountVectorizer(tokenizer=custom_stem_tokenizer)\n",
    "cv.fit(train['OriginalTweet'])\n",
    "cv.transform(train['OriginalTweet'])\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=custom_stem_tokenizer)\n",
    "tfidf.fit(train['OriginalTweet'])\n",
    "tfidf.transform(train['OriginalTweet'])\n",
    "\n",
    "print(len(cv.vocabulary_))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36104\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:39:53.109908Z",
     "start_time": "2025-05-18T14:39:53.106618Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(tfidf.vocabulary_))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36104\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oyzs5TaAoHP6"
   },
   "source": "**Ответ** Очевидно, что словарь чут-чут усох. Дело все в том, что снежным комом мы сжали много слов... До 36104 слов в нашем случае"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OkncHI8oRmd"
   },
   "source": [
    "Обучите логистическую регрессию с использованием обоих векторайзеров. Изменилось ли качество? Есть ли смысл применять стемминг?"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T14:50:42.297679Z",
     "start_time": "2025-05-18T14:44:46.946018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cv_stem = CountVectorizer(tokenizer=custom_stem_tokenizer)\n",
    "cv_stem.fit(X_train)\n",
    "\n",
    "tfidf_stem = TfidfVectorizer(tokenizer=custom_stem_tokenizer)\n",
    "tfidf_stem.fit(X_train)\n",
    "\n",
    "X_tr_cv = cv_stem.transform(X_train)\n",
    "X_te_cv = cv_stem.transform(X_test)\n",
    "X_tr_tfidf = tfidf_stem.transform(X_train)\n",
    "X_te_tfidf = tfidf_stem.transform(X_test)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ykZJPphEoZ5W",
    "ExecuteTime": {
     "end_time": "2025-05-18T14:51:43.690800Z",
     "start_time": "2025-05-18T14:51:43.184971Z"
    }
   },
   "source": [
    "print('cv')\n",
    "classtem_cv = LogisticRegression(max_iter=10000)\n",
    "classtem_cv.fit(X_tr_cv, y_train)\n",
    "y_tr_pred_cv = classtem_cv.predict(X_tr_cv)\n",
    "y_te_pred_cv = classtem_cv.predict(X_te_cv)\n",
    "print(f'train accurasy: {accuracy_score(y_train, y_tr_pred_cv)}')\n",
    "print(f'test accuracy: {accuracy_score(y_test, y_te_pred_cv)}')\n",
    "\n",
    "print('tfidf')\n",
    "classtf_stem = LogisticRegression(max_iter=10000)\n",
    "classtf_stem.fit(X_tr_tfidf, y_train)\n",
    "y_tr_pred_tf = classtf_stem.predict(X_tr_tfidf)\n",
    "y_te_pred_tf = classtf_stem.predict(X_te_tfidf)\n",
    "print(f'train accuracy: {accuracy_score(y_train, y_tr_pred_tf)}')\n",
    "print(f'test accuracy: {accuracy_score(y_test, y_te_pred_tf)}')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv\n",
      "train accurasy: 0.9582656984194788\n",
      "test accuracy: 0.8366553717360973\n",
      "tfidf\n",
      "train accuracy: 0.894788551900897\n",
      "test accuracy: 0.826091289615308\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCRlrODro0h8"
   },
   "source": [
    "**Ответ:** на тестовой выборке почти не изменилось, а вот на трейн чуть-чуть упало. однако словарь уменьшился, в любом случае, это лучше.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYWGQNEDqLC-"
   },
   "source": [
    "## Задание  6 Работа с частотами (1.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Hq-tl5mqUSn"
   },
   "source": [
    "Еще один способ уменьшить количество признаков - это использовать параметры min_df и max_df при построении векторайзера  эти параметры помогают ограничить требуемую частоту встречаемости токена в документах.\n",
    "\n",
    "По умолчанию берутся все токены, которые встретились хотя бы один раз.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1SiD4DE3WZ2"
   },
   "source": "Подберите max_df такой, что размер словаря будет ~~36651 (на 1 меньше, чем было)~~ 36103 (потому что там далеко не 36552, а 36104, расхожесть обсуждалась в беседе основного канала). Почему параметр получился такой большой/маленький?"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3YLb8PViExb",
    "outputId": "b6d67654-d232-4e11-a5ca-6f2145053e98",
    "ExecuteTime": {
     "end_time": "2025-05-19T11:06:32.114942Z",
     "start_time": "2025-05-19T11:05:26.539494Z"
    }
   },
   "source": [
    "cv_df = CountVectorizer(tokenizer=custom_stem_tokenizer,\n",
    "                        min_df=1,\n",
    "                        max_df=8000\n",
    "                        ).fit(\n",
    "                            train['OriginalTweet']\n",
    "                            )\n",
    "print(len(cv_df.vocabulary_))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36103\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T11:10:48.165704Z",
     "start_time": "2025-05-19T11:09:35.876316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tfidf_df = TfidfVectorizer(tokenizer=custom_stem_tokenizer,\n",
    "                        min_df=1,\n",
    "                        max_df=8000\n",
    "                        ).fit(\n",
    "                            train['OriginalTweet']\n",
    "                            )\n",
    "print(len(tfidf_df.vocabulary_))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36103\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdZYoGZR4UsA"
   },
   "source": "**Ответ:** Ну начнем с того что вообще такое min_df и max_df параметры: min_df = 1 оставляет токен, если он встретился в минимум одном документе. То есть все токены. Этот параметр я стал не сильно ломать, но логика у него такая. max_df же делает так, чтоо токен остается если он в НЕ БОЛЕЕ чем n документов. На 10000 у меня было 36104, а на 8000 36103, соответственно один токен куда-то выпал на этом моменте, потому что встречается больше 8000 раз."
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gRIUaB1u32f"
   },
   "source": [
    "Подберите min_df (используйте дефолтное значение max_df) в CountVectorizer таким образом, чтобы размер словаря был 3700 токенов (при использовании токенайзера со стеммингом), а качество осталось таким же, как и было. Что можно сказать о результатах?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSnMJkn9XmsT",
    "outputId": "e0d8eb21-e5d7-46b4-e1d1-4b1ae220e9a0",
    "ExecuteTime": {
     "end_time": "2025-05-19T11:25:18.875673Z",
     "start_time": "2025-05-19T11:24:08.141579Z"
    }
   },
   "source": [
    "cv_df = CountVectorizer(tokenizer=custom_stem_tokenizer,\n",
    "                        min_df=9\n",
    "                        ).fit(\n",
    "                            train['OriginalTweet']\n",
    "                            )\n",
    "print(len(cv_df.vocabulary_))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3939\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T11:26:25.155389Z",
     "start_time": "2025-05-19T11:25:18.970712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cv_df = CountVectorizer(tokenizer=custom_stem_tokenizer,\n",
    "                        min_df=10\n",
    "                        ).fit(\n",
    "                            train['OriginalTweet']\n",
    "                            )\n",
    "print(len(cv_df.vocabulary_))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3680\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mvMDwpdfjm8Y",
    "ExecuteTime": {
     "end_time": "2025-05-19T11:29:21.833275Z",
     "start_time": "2025-05-19T11:28:12.170741Z"
    }
   },
   "source": [
    "tfidf_df = TfidfVectorizer(tokenizer=custom_stem_tokenizer,\n",
    "                        min_df=9\n",
    "                        ).fit(\n",
    "                            train['OriginalTweet']\n",
    "                            )\n",
    "print(len(cv_df.vocabulary_))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3680\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fGYpUIZx0fk"
   },
   "source": "**Ответ:** 3939 и 3680 с какой стати??? Вероятно из-за разности в количестве слов как и ранее. Так что добиться такого невозможно с текущими данными. Но в любом случае размер мы уменьшили, пояснение за то как работает min_df прикрепил выше."
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx_h_-inKbBl"
   },
   "source": [
    "В предыдущих заданиях признаки не скалировались. Отскалируйте данные (при словаре размера 3.7 тысяч, векторизованные CountVectorizer), обучите логистическую регрессию, посмотрите качество и выведите `barplot`, содержащий по 10 токенов, с наибольшим по модулю положительными/отрицательными весами. Что можно сказать об этих токенах?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktJVOdrIHq7B"
   },
   "source": [
    "## Задание 7 Другие признаки (1.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yt3jRCZ2H0Og"
   },
   "source": [
    "Мы были сконцентрированы на работе с текстами твиттов и не использовали другие признаки - имена пользователя, дату и местоположение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52wjewCCo_di"
   },
   "source": [
    "Изучите признаки UserName и ScreenName. полезны ли они? Если полезны, то закодируйте их, добавьте к матрице с отскалированными признаками, обучите логистическую регрессию, замерьте качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63thouYZptj6"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8_qR-gnpT3a"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ythEcFSkt7y3"
   },
   "source": [
    "Изучите признак TweetAt в обучающей выборке: преобразуйте его к типу datetime и нарисуйте его гистограмму с разделением по цвету на основе целевой переменной. Полезен ли он? Если полезен, то закодируйте его, добавьте к матрице с отскалированными признаками, обучите логистическую регрессию, замерьте качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lxb_k0JLirNv"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IdLBdpQxM-G"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2JtRPhNP6qx"
   },
   "source": [
    "Поработайте с признаком Location в обучающей выборке. Сколько уникальных значений?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYQZQ1FRNpoe"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6k4JwpRTQISa"
   },
   "source": [
    "Постройте гистограмму топ-10 по популярности местоположений (исключая Unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J91YkhegJ0mz"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOsv3lODTfYB"
   },
   "source": [
    "Видно, что многие местоположения включают в себя более точное название места, чем другие (Например, у некоторых стоит London, UK; а у некоторых просто UK или United Kingdom).\n",
    "\n",
    "Создайте новый признак WiderLocation, который содержит самое широкое местоположение (например, из London, UK должно получиться UK). Сколько уникальных категорий теперь? Постройте аналогичную гистограмму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSkow6acOMyD"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgyWrD2eVfff"
   },
   "source": [
    "Закодируйте признак WiderLocation с помощью OHE таким образом, чтобы создались только столбцы для местоположений, которые встречаются более одного раза. Сколько таких значений?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeJBfBWgPvg_"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyMX5kZuimPK"
   },
   "source": [
    "Добавьте этот признак к матрице отскалированных текстовых признаков, обучите логистическую регрессию, замерьте качество. Как оно изменилось? Оказался ли признак полезным?\n",
    "\n",
    "\n",
    "*Подсказка:* используйте параметр `categories` в энкодере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EO1jNPeeim7A"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dHsGlDRYUQt"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
